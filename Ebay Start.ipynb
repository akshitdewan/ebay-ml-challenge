{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 3,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#akshit_df = './mlchallenge_set_2021.tsv'\n",
    "#akshit_valid = './mlchallenge_set_validation.tsv'\n",
    "sam_df = 'C:/Users/sjmal/OneDrive/Desktop/ML/2021/mlchallenge_set_2021_edited.txt'\n",
    "sam_valid = 'C:/Users/sjmal/OneDrive/Desktop/ML/2021/mlchallenge_set_validation.tsv'\n",
    "df = pd.read_table(sam_df)\n",
    "valid = pd.read_table(sam_valid,sep='\\t')\n",
    "df.columns=['category','primary_image_url','All Links','Tags','index']\n",
    "valid.columns=['ID', 'Group']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 64,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "2480\n"
     ]
    }
   ],
   "source": [
    "#create dictionary of groups with list of IDs in that group\n",
    "dict = {}\n",
    "total=0\n",
    "for index,row in valid.iterrows():\n",
    "    if row['Group'] in dict:\n",
    "        dict[row['Group']].append(row['ID'])\n",
    "    else:\n",
    "        dict[row['Group']] = [row['ID']]\n",
    "#list of groups with multiple IDs\n",
    "matches = []\n",
    "for key,value in dict.items():\n",
    "    if len(value) > 1:\n",
    "        total+=len(value)\n",
    "        matches.append(key)\n",
    "print(len(matches))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 65,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category                                  primary_image_url  \\\n",
      "0         2  https://i.ebayimg.com/00/s/MTA1OFgxMTM0/z/KPIA...   \n",
      "1         2  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/flIA...   \n",
      "2         2  http://i.ebayimg.com/00/s/ODAwWDEwNjc=/z/XHcAA...   \n",
      "3         2  https://i.ebayimg.com/00/s/MTA2N1gxNjAw/z/scsA...   \n",
      "4         2  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/HDIA...   \n",
      "\n",
      "                                           All Links  \\\n",
      "0  https://i.ebayimg.com/00/s/MTA1OFgxMTM0/z/KPIA...   \n",
      "1  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/flIA...   \n",
      "2  http://i.ebayimg.com/00/s/ODAwWDEwNjc=/z/XHcAA...   \n",
      "3  https://i.ebayimg.com/00/s/MTA2N1gxNjAw/z/scsA...   \n",
      "4  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/HDIA...   \n",
      "\n",
      "                                                Tags  index  \n",
      "0  (Color:Gray/White,Country/Region of Manufactur...      1  \n",
      "1  (Style:Cleats,Color:White Orange,US Shoe Size ...      2  \n",
      "2  (Width:Medium (D, M),US Size:9,Brand:VANS,Colo...      3  \n",
      "3  (US Shoe Size (Men's):10.5,Material:Enter item...      4  \n",
      "4  (US Shoe Size (Men's):7,Brand:AMA BRAND,Color:...      5  \n",
      "    ID    Group\n",
      "0  194  2000003\n",
      "1  251  2000004\n",
      "2  315  2000006\n",
      "3  321  2000007\n",
      "4  424  2000008\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(valid.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 3,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5e0f35be6386>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['All Links'][i] = link.split(';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/iYY...\n",
      "1     [https://i.ebayimg.com/00/s/MTA1OFgxMTM0/z/KPI...\n",
      "2     [https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/flI...\n",
      "3     [http://i.ebayimg.com/00/s/ODAwWDEwNjc=/z/XHcA...\n",
      "4     [https://i.ebayimg.com/00/s/MTA2N1gxNjAw/z/scs...\n",
      "                            ...                        \n",
      "95    [https://i.ebayimg.com/00/s/MTU5OVgxNTgx/z/vMA...\n",
      "96    [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/GoA...\n",
      "97    [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/Hm0...\n",
      "98    [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/VhA...\n",
      "99    [https://i.ebayimg.com/00/s/MTYwMFgxNjAw/z/n4o...\n",
      "Name: All Links, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#split links into list (for now only does first 100)\n",
    "i = 0\n",
    "for link in df['All Links'][0:100]:\n",
    "    df['All Links'][i] = link.split(';')\n",
    "    i+=1\n",
    "print(df['All Links'][0:100])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 14,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def register_attributes(attribute, all_attributes):\n",
    "    attribute = re.sub(r'[()]','', attribute)\n",
    "    attribute = re.split(r',', attribute)\n",
    "    attribute = [a.split(':') for a in attribute]\n",
    "    for i, a in enumerate(attribute):\n",
    "        attribute[i] = [s.strip() for s in a]\n",
    "        all_attributes.add(attribute[i][0])\n",
    "    #print(f'atttribute is: {attribute}')\n",
    "    mapping = {}\n",
    "    #for i in range(len(attribute) - 1):\n",
    "    #    if i == len(attribute) - 2:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:]\n",
    "    #    else:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:-1]\n",
    "    return(attribute)\n",
    "\n",
    "def map_attributes(attribute, num_attributes, index_to_attr):\n",
    "    attribute = re.sub(r'[()]','', attribute)\n",
    "    attribute = re.split(r',', attribute)\n",
    "    attribute = [a.split(':') for a in attribute]\n",
    "    all_attributes_for_row = [None] * num_attributes\n",
    "    for i, a in enumerate(attribute):\n",
    "        attribute[i] = [s.strip() for s in a]\n",
    "        #print(f'index: {attr_to_index[attribute[i][0]]}')\n",
    "        if len(attribute[i]) > 1:\n",
    "            all_attributes_for_row[attr_to_index[attribute[i][0]]] = attribute[i][1]\n",
    "    mapping = {}\n",
    "    #for i in range(len(attribute) - 1):\n",
    "    #    if i == len(attribute) - 2:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:]\n",
    "    #    else:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:-1]\n",
    "    return all_attributes_for_row\n",
    "m = 2000\n",
    "all_attributes = set()\n",
    "all_maps = []\n",
    "for index,row in df[0:m].iterrows():\n",
    "    register_attributes(row['Tags'], all_attributes)\n",
    "\n",
    "all_attributes = list(all_attributes)\n",
    "attr_to_index = {all_attributes[i]: i for i in range(len(all_attributes))}\n",
    "#print(attr_to_index)\n",
    "#print(f'numAttributes: {len(all_attributes)}')\n",
    "\n",
    "for index,row in df[0:m].iterrows():\n",
    "    all_maps.append(map_attributes(row['Tags'], len(all_attributes), attr_to_index))\n",
    "#print(all_maps)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       0     1     2     3     4     5     6      7     8     9    ...   309  \\\n0     None  None  None  None  None  None  None   None  None  None  ...  None   \n1     None  None  None  None  None  None  None   None  None  None  ...  None   \n2     None  None  None  None  None  None  None   None  None  None  ...  None   \n3     None  None  None  None  None  None  None   None  None  None  ...  None   \n4     None  None  None  None  None  None  None   None  None  None  ...  None   \n...    ...   ...   ...   ...   ...   ...   ...    ...   ...   ...  ...   ...   \n1995  None  None  None  None  None  None  None   None  None  None  ...  None   \n1996  None  None  None  None  None  None  None   None  None  None  ...  None   \n1997  None  None  None  None  None  None  None   None  None  None  ...  None   \n1998  None  None  None  None  None  None  None  52642  None  None  ...  None   \n1999  None  None  None  None  None  None  None  65659  None  None  ...  None   \n\n       310   311   312   313   314   315   316   317   318  \n0     None  None  None  None  None  None  None  None  None  \n1     None  None  None  None  None  None  None  None  None  \n2     None  None  None  None  None  None  None  None  None  \n3     None  None  None  None  None  None  None  None  None  \n4     None  None  None  None  None  None  None  None  None  \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n1995  None  None  None  None  None  None  None  None  None  \n1996  None  None  None  None  None  None  None  None  None  \n1997  None  None  None  None  None  None  None  None  None  \n1998  None  None  None  None  None  None  None  None  None  \n1999  None  None  None  None  None  None  None  None  None  \n\n[2000 rows x 319 columns]\n"
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1     2     3     4     5     6     7     8     9    ...   309  \\\n",
      "0     None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "1     None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "2     None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "3     None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "4     None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "1995  None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "1996  None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "1997  None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "1998  None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "1999  None  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "\n",
      "       310   311   312        313   314   315   316   317   318  \n",
      "0     None  None  None       None  None  None  None  None  None  \n",
      "1     None  None  None  Indonesia  None  None  None  None  None  \n",
      "2     None  None  None       None  None  None  None  None  None  \n",
      "3     None  None  None       None  None  None  None  None  None  \n",
      "4     None  None  None       None  None  None  None  None  None  \n",
      "...    ...   ...   ...        ...   ...   ...   ...   ...   ...  \n",
      "1995  None  None  None       None  None  None  None  None  None  \n",
      "1996  None  None  None      China  None  None  None  None  None  \n",
      "1997  None  None  None       None  None  None  None  None  None  \n",
      "1998  None  None  None       None  None  None  None  None  None  \n",
      "1999  None  None  None       None  None  None  None  None  None  \n",
      "\n",
      "[2000 rows x 319 columns]\n"
>>>>>>> refs/remotes/origin/master
     ]
    }
   ],
   "source": [
    "#dataframe with attribute values\n",
    "categories = pd.DataFrame(all_maps)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 11)\t1.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 19)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 31)\t1.0\n",
      "  (0, 32)\t1.0\n",
      "  (0, 78)\t1.0\n",
      "  (0, 79)\t1.0\n",
      "  (0, 82)\t1.0\n",
      "  (0, 83)\t1.0\n",
      "  :\t:\n",
      "  (1999, 3318)\t1.0\n",
      "  (1999, 3319)\t1.0\n",
      "  (1999, 3320)\t1.0\n",
      "  (1999, 3322)\t1.0\n",
      "  (1999, 3324)\t1.0\n",
      "  (1999, 3328)\t1.0\n",
      "  (1999, 3332)\t1.0\n",
      "  (1999, 3333)\t1.0\n",
      "  (1999, 3336)\t1.0\n",
      "  (1999, 3337)\t1.0\n",
      "  (1999, 3340)\t1.0\n",
      "  (1999, 3341)\t1.0\n",
      "  (1999, 3342)\t1.0\n",
      "  (1999, 3343)\t1.0\n",
      "  (1999, 3344)\t1.0\n",
      "  (1999, 3345)\t1.0\n",
      "  (1999, 3346)\t1.0\n",
      "  (1999, 3347)\t1.0\n",
      "  (1999, 3348)\t1.0\n",
      "  (1999, 3349)\t1.0\n",
      "  (1999, 3350)\t1.0\n",
      "  (1999, 3351)\t1.0\n",
      "  (1999, 3352)\t1.0\n",
      "  (1999, 3353)\t1.0\n",
      "  (1999, 3355)\t1.0\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "x = OneHotEncoder().fit_transform(categories)\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering(compute_distances=True, compute_full_tree=True,\n",
      "                        distance_threshold=1.5, n_clusters=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering(compute_distances=True,compute_full_tree = True,distance_threshold = 1.5,n_clusters=None).fit(x.todense())\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELS\n",
      "[ 921 1653 1173 ...  572  285  170]\n",
      "2000\n",
      "1765\n",
      "DISTAnCES\n",
      "[ 0.          0.          0.         ... 34.87119155 43.63236752\n",
      " 67.88776103]\n",
      "num connected components\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"LABELS\")\n",
    "print(clustering.labels_)\n",
    "print(len(clustering.labels_))\n",
    "print(len(set(clustering.labels_)))\n",
    "print(\"DISTAnCES\")\n",
    "print(clustering.distances_)\n",
    "print(\"num connected components\")\n",
    "print(clustering.n_connected_components_)\n",
    "# make this better\n",
    "# make this work on the entire dataset\n",
    "# fix nonetypes\n",
    "# don't punish missing attributes, but punish conflicts. how do we encode this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {}\n",
    "for i, label in enumerate(clustering.labels_):\n",
    "    if label not in groups:\n",
    "        groups[label] = []\n",
    "    groups[label].append(i)\n",
    "groups = {label: groups[label] for label in groups if len(groups[label]) > 1}\n",
    "print(groups)\n",
    "for label in groups:\n",
    "    print(f'GROUP: {label}')\n",
    "    for item in groups[label]:\n",
    "        print(df['Tags'][item])\n",
    "    print('-----------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    \n",
    "    link_labels = [df['Tags'][i] for i in clustering.labels_]\n",
    "    dendrogram(linkage_matrix, labels = link_labels)\n",
    "plot_dendrogram(clustering)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "freq=Counter()\n",
    "attribute=[['']]*len(df)\n",
    "trialrange=100\n",
    "for x in range(trialrange):#range(int(len(df)/10)):#len(df)\n",
    "    attribute[x]=df.iloc[x,3].lower()\n",
    "    attribute[x] = re.sub(r'[()]','', attribute[x])\n",
    "    attribute[x] = re.split(r',', attribute[x])\n",
    "    attribute[x] = [a.split(':') for a in attribute[x]]\n",
    "    freq+=Counter([i[0] for i in attribute[x]])\n",
    "    tempdict={}\n",
    "    for i in attribute[x]:\n",
    "\n",
    "            try:\n",
    "                tempdict[i[0]]=float(i[1])\n",
    "            except:\n",
    "                try:\n",
    "                    tempdict[i[0]]=i[1]\n",
    "                except:\n",
    "                    pass\n",
    "    attribute[x]=tempdict\n",
    "\n",
    "df['seg']=attribute\n",
    "#print(df['seg'])"
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_brand = []\n",
    "\n",
    "for index, row in df[0:1000].iterrows():\n",
    "    if 'Brand' in row['Tags']:\n",
    "        has_brand.append(row['primary_image_url'])\n",
    "print(len(has_brand)\n",
    "'''\n",
    "i = 0\n",
    "for index,row in categories[0:1000].iterrows():\n",
    "      if row['Brand'] is not 'None':\n",
    "          has_brand.append(np.asarray(df['primary_image_url'][index]))\n",
    "      i+=1\n",
    "print(len(has_brand))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "'''\n",
    "url = df['primary_image_url'][4]\n",
    "response = requests.get(url)\n",
    "#img = Image.open(BytesIO(response.content))\n",
    "img = Image.open(requests.get(url, stream=True).raw)\n",
    "img.show()\n",
    "result = Image.new(img.mode, (1000, 550), (64,64,64))\n",
    "result.paste(img, (0, 0))\n",
    "result.show()\n",
    "print(np.asarray(img).shape)\n",
    "print(np.asarray(result).shape)\n",
    "'''\n",
    "image_array = []\n",
    "max_height = 0\n",
    "max_width = 0\n",
    "for img in df['primary_image_url'][0:1000]:\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    if np.asarray(img).shape[1] > max_width:\n",
    "        max_width = np.asarray(img).shape[1]\n",
    "    if np.asarray(img).shape[0] > max_height:\n",
    "        max_height = np.asarray(img).shape[0]\n",
    "\n",
    "for img in df['primary_image_url'][0:1000]:\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    margin = Image.new(img.mode, (max_width, max_height), (64,64,64))\n",
    "    margin.paste(img, (0, 0))\n",
    "    image_array.append(np.asarray(margin))"
>>>>>>> refs/remotes/origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n"
=======
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 500, 3)\n"
>>>>>>> refs/remotes/origin/master
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "Brands=[]\n",
    "Images=[]\n",
    "print(trialrange)\n",
    "for i in range(trialrange):\n",
    "    try:\n",
    "        #df['seg'].iloc[i]['brand']\n",
    "        #df['primary_image_url'].iloc[i]\n",
    "        #print(df['seg'].iloc[i]['brand'])\n",
    "        #print(df['primary_image_url'].iloc[i])\n",
    "        Brands.append(df['seg'].iloc[i]['brand'])\n",
    "        Images.append(df['primary_image_url'].iloc[i])\n",
    "    except:\n",
    "        print('not possible at: ',i)"
=======
    "print(image_array[51].shape)"
>>>>>>> refs/remotes/origin/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(400, 300, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "m = 100\n",
    "train_images = data[0:m*.8]\n",
    "test_images = data[m*.8:]\n",
    "train_labels = labels[0:m*.8]\n",
    "test_labels = labels[m*.8:]\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
