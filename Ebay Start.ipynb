{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sam_df_path = 'C:/Users/sjmal/OneDrive/Desktop/ML/2021/mlchallenge_set_2021_edited.txt'\n",
    "sam_valid_path\n",
    "df = pd.read_table()\n",
    "valid = pd.read_table('C:/Users/sjmal/OneDrive/Desktop/ML/2021/mlchallenge_set_validation.tsv',sep='\\t')\n",
    "df.columns=['category','primary_image_url','All Links','Tags','ID']\n",
    "valid.columns=['ID', 'Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "2480\n"
     ]
    }
   ],
   "source": [
    "#create dictionary of groups with list of IDs in that group\n",
    "dict = {}\n",
    "total=0\n",
    "for index,row in valid.iterrows():\n",
    "    if row['Group'] in dict:\n",
    "        dict[row['Group']].append(row['ID'])\n",
    "    else:\n",
    "        dict[row['Group']] = [row['ID']]\n",
    "#list of groups with multiple IDs\n",
    "matches = []\n",
    "for key,value in dict.items():\n",
    "    if len(value) > 1:\n",
    "        total+=len(value)\n",
    "        matches.append(key)\n",
    "print(len(matches))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category                                          Main Link  \\\n",
      "0         2  https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/iYYA...   \n",
      "1         2  https://i.ebayimg.com/00/s/MTA1OFgxMTM0/z/KPIA...   \n",
      "2         2  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/flIA...   \n",
      "3         2  http://i.ebayimg.com/00/s/ODAwWDEwNjc=/z/XHcAA...   \n",
      "4         2  https://i.ebayimg.com/00/s/MTA2N1gxNjAw/z/scsA...   \n",
      "\n",
      "                                           All Links  \\\n",
      "0  https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/iYYA...   \n",
      "1  https://i.ebayimg.com/00/s/MTA1OFgxMTM0/z/KPIA...   \n",
      "2  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/flIA...   \n",
      "3  http://i.ebayimg.com/00/s/ODAwWDEwNjc=/z/XHcAA...   \n",
      "4  https://i.ebayimg.com/00/s/MTA2N1gxNjAw/z/scsA...   \n",
      "\n",
      "                                                Tags  ID  \n",
      "0  (Brand:Shimano,US Shoe Size (Men's):4.5,Modifi...   0  \n",
      "1  (Color:Gray/White,Country/Region of Manufactur...   1  \n",
      "2  (Style:Cleats,Color:White Orange,US Shoe Size ...   2  \n",
      "3  (Width:Medium (D, M),US Size:9,Brand:VANS,Colo...   3  \n",
      "4  (US Shoe Size (Men's):10.5,Material:Enter item...   4  \n",
      "    ID    Group\n",
      "0  163  2000001\n",
      "1  194  2000003\n",
      "2  251  2000004\n",
      "3  315  2000006\n",
      "4  321  2000007\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5e0f35be6386>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['All Links'][i] = link.split(';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/iYY...\n",
      "1     [https://i.ebayimg.com/00/s/MTA1OFgxMTM0/z/KPI...\n",
      "2     [https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/flI...\n",
      "3     [http://i.ebayimg.com/00/s/ODAwWDEwNjc=/z/XHcA...\n",
      "4     [https://i.ebayimg.com/00/s/MTA2N1gxNjAw/z/scs...\n",
      "                            ...                        \n",
      "95    [https://i.ebayimg.com/00/s/MTU5OVgxNTgx/z/vMA...\n",
      "96    [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/GoA...\n",
      "97    [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/Hm0...\n",
      "98    [https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/VhA...\n",
      "99    [https://i.ebayimg.com/00/s/MTYwMFgxNjAw/z/n4o...\n",
      "Name: All Links, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#split links into list (for now only does first 100)\n",
    "i = 0\n",
    "for link in df['All Links'][0:100]:\n",
    "    df['All Links'][i] = link.split(';')\n",
    "    i+=1\n",
    "print(df['All Links'][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def register_attributes(attribute, all_attributes):\n",
    "    attribute = re.sub(r'[()]','', attribute)\n",
    "    attribute = re.split(r',', attribute)\n",
    "    attribute = [a.split(':') for a in attribute]\n",
    "    for i, a in enumerate(attribute):\n",
    "        attribute[i] = [s.strip() for s in a]\n",
    "        all_attributes.add(attribute[i][0])\n",
    "    #print(f'atttribute is: {attribute}')\n",
    "    mapping = {}\n",
    "    #for i in range(len(attribute) - 1):\n",
    "    #    if i == len(attribute) - 2:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:]\n",
    "    #    else:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:-1]\n",
    "    return(attribute)\n",
    "\n",
    "def map_attributes(attribute, num_attributes, index_to_attr):\n",
    "    attribute = re.sub(r'[()]','', attribute)\n",
    "    attribute = re.split(r',', attribute)\n",
    "    attribute = [a.split(':') for a in attribute]\n",
    "    all_attributes_for_row = [None] * num_attributes\n",
    "    for i, a in enumerate(attribute):\n",
    "        attribute[i] = [s.strip() for s in a]\n",
    "        #print(f'index: {attr_to_index[attribute[i][0]]}')\n",
    "        if len(attribute[i]) > 1:\n",
    "            all_attributes_for_row[attr_to_index[attribute[i][0]]] = attribute[i][1]\n",
    "    mapping = {}\n",
    "    #for i in range(len(attribute) - 1):\n",
    "    #    if i == len(attribute) - 2:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:]\n",
    "    #    else:\n",
    "    #        mapping[attribute[i][-1]] = attribute[i + 1][:-1]\n",
    "    return all_attributes_for_row\n",
    "\n",
    "all_attributes = set()\n",
    "all_maps = []\n",
    "for index,row in df[0:5000].iterrows():\n",
    "    register_attributes(row['Tags'], all_attributes)\n",
    "\n",
    "all_attributes = list(all_attributes)\n",
    "attr_to_index = {all_attributes[i]: i for i in range(len(all_attributes))}\n",
    "#print(attr_to_index)\n",
    "#print(f'numAttributes: {len(all_attributes)}')\n",
    "\n",
    "for index,row in df[0:5000].iterrows():\n",
    "    all_maps.append(map_attributes(row['Tags'], len(all_attributes), attr_to_index))\n",
    "#print(all_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe with attribute values\n",
    "categories = pd.DataFrame(all_maps)\n",
    "#print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.6 MiB for an array with shape (3035000,) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-3e4e19cdd73c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sjmal\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \"\"\"\n\u001b[0;32m    442\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sjmal\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sjmal\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mfeature_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_int\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeature_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.6 MiB for an array with shape (3035000,) and data type int32"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "x = OneHotEncoder().fit_transform(categories)\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering(compute_distances=True, compute_full_tree=True,\n",
      "                        distance_threshold=0.01, n_clusters=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering(compute_distances=True,compute_full_tree = True,distance_threshold = .01,n_clusters=None).fit(x.todense())\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95 61 55 51 62 64 78  0 91 83 79 87 50 76 70 52 98 97 86 93 81 85 90 56\n",
      " 67 80 66 96 65 84 49 42 47 27 74  0 57 32 94 92 63 45 68 89 46 88 39 24\n",
      " 59 22 43 75 53 72 30 60 77 41 82 29 71 54 25 73 69 58 33 20 48 40 23 38\n",
      " 37 44 26 14 35 34 19 21 28 10  9 31 18 36  4 15 16 17  8 13  7  3 12  6\n",
      " 11  5  1  2]\n",
      "[0.         1.41421356 1.41421356 1.41421356 1.41421356 1.41421356\n",
      " 1.41421356 1.41421356 1.41421356 1.41421356 1.82574186 1.91485422\n",
      " 2.         2.         2.         2.         2.         2.\n",
      " 2.         2.         2.         2.         2.         2.\n",
      " 2.1602469  2.1602469  2.1602469  2.23606798 2.28035085 2.30940108\n",
      " 2.30940108 2.30940108 2.30940108 2.30940108 2.4377976  2.44948974\n",
      " 2.44948974 2.44948974 2.44948974 2.44948974 2.44948974 2.44948974\n",
      " 2.44948974 2.5819889  2.5819889  2.5819889  2.7080128  2.7080128\n",
      " 2.7080128  2.7080128  2.76887462 2.82842712 2.82842712 2.82842712\n",
      " 2.82842712 2.82842712 3.         3.         3.05505046 3.05505046\n",
      " 3.16227766 3.26598632 3.32665999 3.33809184 3.36650165 3.43511281\n",
      " 3.46410162 3.46410162 3.54024481 3.55902608 3.61478446 3.62092683\n",
      " 3.65148372 3.65148372 3.74165739 3.77123617 3.77439157 3.82970843\n",
      " 3.86436713 3.96412484 3.96652661 3.98179618 4.02246439 4.02492236\n",
      " 4.0824829  4.30979802 4.42950481 4.45078912 4.52856892 4.77571557\n",
      " 4.89897949 5.03686047 5.2981254  5.75246983 5.94947648 6.30936453\n",
      " 6.39199842 6.70228127 9.92265163]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(clustering.labels_)\n",
    "print(clustering.distances_)\n",
    "print(clustering.n_connected_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'set_urls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-5dd9c100253b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mdendrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinkage_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mplot_dendrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_urls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Main Link'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclustering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'set_urls'"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    #response = requests.get(url)\n",
    "    #img = Image.open(BytesIO(response.content))\n",
    "    link_labels = [df['Tags'][i] for i in clustering.labels_]\n",
    "    dendrogram(linkage_matrix, labels = link_labels)\n",
    "plot_dendrogram(clustering)\n",
    "plt.set_urls(df['Main Link'][i] for i in clustering.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.9.1), accessed by source activate my",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
