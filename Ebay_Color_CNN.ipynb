{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ebay Color CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyucnuEG0zmE"
      },
      "source": [
        "import pandas as pd\r\n",
        "akshit_df = './mlchallenge_set_2021.tsv'\r\n",
        "akshit_valid = './mlchallenge_set_validation.tsv'\r\n",
        "sam_df = './drive/MyDrive/mlchallenge_set_2021_edited.txt'\r\n",
        "#sam_valid = './mlchallenge_set_validation.tsv'\r\n",
        "#SA_valid=pd.read_table('/Users/shivankagrawal/Documents/ebay/mlchallenge_set_validation.tsv',header=None)\r\n",
        "#SA_df=pd.read_table('/Users/shivankagrawal/Documents/ebay/mlchallenge_set_2021.tsv',header=None)\r\n",
        "#df=SA_df\r\n",
        "#valid=SA_valid\r\n",
        "df = pd.read_table(sam_df)\r\n",
        "#valid = pd.read_table(sam_valid,sep='\\t')\r\n",
        "df.columns=['category','primary_image_url','All Links','Tags','index']\r\n",
        "#valid.columns=['ID', 'Group']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RubkU9F604iD"
      },
      "source": [
        "import re\r\n",
        "from collections import Counter\r\n",
        "freq=Counter()\r\n",
        "attribute=[['']]*len(df)\r\n",
        "trialrange=10000\r\n",
        "for x in range(trialrange):#range(int(len(df)/10)):#len(df)\r\n",
        "    attribute[x]=df.iloc[x,3].lower()\r\n",
        "    attribute[x] = re.sub(r'[()]','', attribute[x])\r\n",
        "    attribute[x] = re.split(r',', attribute[x])\r\n",
        "    attribute[x] = [a.split(':') for a in attribute[x]]\r\n",
        "    freq+=Counter([i[0] for i in attribute[x]])\r\n",
        "    tempdict={}\r\n",
        "    for i in attribute[x]:\r\n",
        "            try:\r\n",
        "                tempdict[i[0]]=float(i[1])\r\n",
        "            except:\r\n",
        "                try:\r\n",
        "                    tempdict[i[0]]=i[1]\r\n",
        "                except:\r\n",
        "                    pass\r\n",
        "    attribute[x]=tempdict\r\n",
        "\r\n",
        "df['seg']=attribute\r\n",
        "#print(df['seg'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLp4u1-xhr9c"
      },
      "source": [
        "for i in df['seg'][0:trialrange]:\r\n",
        "  if 'color' in i:\r\n",
        "    i['color']=re.split(r'[-\\s,/]', i['color'])\r\n",
        "    #print(i['color'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiw3Ynfn07YS"
      },
      "source": [
        "Brands=[]\r\n",
        "Images=[]\r\n",
        "Colors = []\r\n",
        "color_images = []\r\n",
        "simple_colors = {'black','white','red','blue','green','yellow','brown','purple','pink','gray','grey'}\r\n",
        "print(trialrange)\r\n",
        "for i in range(trialrange):\r\n",
        "    try:\r\n",
        "        for word in df['seg'].iloc[i]['color']:\r\n",
        "            if word in simple_colors:\r\n",
        "              Colors.append(word)\r\n",
        "              color_images.append(df['primary_image_url'].iloc[i])\r\n",
        "              break\r\n",
        "    except:\r\n",
        "        continue\r\n",
        "#print(Colors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUDBYsvt1CKM"
      },
      "source": [
        "n = 2500\r\n",
        "from PIL import Image, ImageFile\r\n",
        "import requests\r\n",
        "import urllib.request\r\n",
        "from io import BytesIO\r\n",
        "import numpy as np\r\n",
        "import grequests\r\n",
        "import pycurl\r\n",
        "\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
        "image_array = []\r\n",
        "images = []\r\n",
        "max_height = 0\r\n",
        "max_width = 0\r\n",
        "i = 0\r\n",
        "\r\n",
        "def loadImage(URL):\r\n",
        "    with urllib.request.urlopen(URL) as url:\r\n",
        "        img = Image.open(BytesIO(url.read()))\r\n",
        "    return img\r\n",
        "\r\n",
        "for url in color_images[0:n]:\r\n",
        "    if i%500 == 0:\r\n",
        "      print(i)\r\n",
        "    i+=1\r\n",
        "    img = loadImage(url)\r\n",
        "    img = img.convert('RGB')\r\n",
        "    img = img.resize((200,200))\r\n",
        "    pix=np.asarray(img)\r\n",
        "    pix=pix.astype('float32')\r\n",
        "    pix/=255.0\r\n",
        "    images.append(pix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeFok-oa1GBx"
      },
      "source": [
        "color_dict = {}\r\n",
        "num = 0\r\n",
        "labels = []\r\n",
        "for b in Colors:\r\n",
        "    if b not in color_dict:\r\n",
        "        color_dict[b] = num\r\n",
        "        num+=1\r\n",
        "    labels.append(color_dict[b])\r\n",
        "print(len(labels))\r\n",
        "m = 2000\r\n",
        "n = round(m*.8)\r\n",
        "from collections import Counter\r\n",
        "print(Counter(labels[0:2500]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka4Kmmi51D-r"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import datasets, layers, models\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Conv2D(8, (3, 3), activation='softmax', input_shape=(200, 200, 3)))\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(64, activation='softmax'))\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(epsilon=.01),\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl9wtJfk8Ixu"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='softmax', input_shape=(200, 200, 3)))\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='softmax'))\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='softmax'))\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(64, activation='softmax'))\r\n",
        "model.add(layers.Dense(32))\r\n",
        "\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(epsilon=.01),\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwaEb9OM1Iuq"
      },
      "source": [
        "m = 2500\r\n",
        "history = model.fit(np.asarray(images[0:m]), np.asarray(labels[0:m],np.int16), epochs=50, batch_size = 500,validation_split=.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvwCzp3Pb3KV"
      },
      "source": [
        "needs_color = []\r\n",
        "for x in df['seg'][0:trialrange]:\r\n",
        "  if 'color' not in x.keys() and 'colour' not in x.keys():\r\n",
        "      needs_color.append(x)\r\n",
        "print(len(needs_color))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}